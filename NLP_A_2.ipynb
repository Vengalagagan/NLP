{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMib/8bbjoMbTgOb0IOX2eA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vengalagagan/NLP/blob/main/NLP_A_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take Medical Report"
      ],
      "metadata": {
        "id": "PWogHZHJUk5B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Medical = \"\"\"\n",
        "Patients suffering from diabetes mellitus require continuous monitoring of blood glucose levels.\n",
        "Medications are administered to reduce complications such as neuropathy and cardiovascular diseases.\n",
        "Early diagnosis improves treatment outcomes and reduces mortality rates.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QSD81TrzRDyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Packages"
      ],
      "metadata": {
        "id": "WVVNknHCTXPn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIbFw6CHPhJT",
        "outputId": "1afb72de-31dc-4116-cdf0-fca0966fa289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Patients',\n",
              " 'suffering',\n",
              " 'from',\n",
              " 'diabetes',\n",
              " 'mellitus',\n",
              " 'require',\n",
              " 'continuous',\n",
              " 'monitoring',\n",
              " 'of',\n",
              " 'blood',\n",
              " 'glucose',\n",
              " 'levels',\n",
              " '.',\n",
              " 'Medications',\n",
              " 'are',\n",
              " 'administered',\n",
              " 'to',\n",
              " 'reduce',\n",
              " 'complications',\n",
              " 'such',\n",
              " 'as',\n",
              " 'neuropathy',\n",
              " 'and',\n",
              " 'cardiovascular',\n",
              " 'diseases',\n",
              " '.',\n",
              " 'Early',\n",
              " 'diagnosis',\n",
              " 'improves',\n",
              " 'treatment',\n",
              " 'outcomes',\n",
              " 'and',\n",
              " 'reduces',\n",
              " 'mortality',\n",
              " 'rates',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(Medical)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization"
      ],
      "metadata": {
        "id": "rm3QuD33Yh8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(Medical)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8360QvmORrtC",
        "outputId": "552c680a-a94f-4aa4-f910-dfaa9521544b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\nPatients suffering from diabetes mellitus require continuous monitoring of blood glucose levels.',\n",
              " 'Medications are administered to reduce complications such as neuropathy and cardiovascular diseases.',\n",
              " 'Early diagnosis improves treatment outcomes and reduces mortality rates.']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering Stop Words"
      ],
      "metadata": {
        "id": "vYEpWjkUTwJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGkh_nP1R6rI",
        "outputId": "7a3105d0-7905-49c3-a78c-7d2b25b4fd45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize(Medical)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5vfeaDGSKhI",
        "outputId": "063264f6-cdf9-4f72-ca3b-ff64d5952602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Patients',\n",
              " 'suffering',\n",
              " 'from',\n",
              " 'diabetes',\n",
              " 'mellitus',\n",
              " 'require',\n",
              " 'continuous',\n",
              " 'monitoring',\n",
              " 'of',\n",
              " 'blood',\n",
              " 'glucose',\n",
              " 'levels',\n",
              " '.',\n",
              " 'Medications',\n",
              " 'are',\n",
              " 'administered',\n",
              " 'to',\n",
              " 'reduce',\n",
              " 'complications',\n",
              " 'such',\n",
              " 'as',\n",
              " 'neuropathy',\n",
              " 'and',\n",
              " 'cardiovascular',\n",
              " 'diseases',\n",
              " '.',\n",
              " 'Early',\n",
              " 'diagnosis',\n",
              " 'improves',\n",
              " 'treatment',\n",
              " 'outcomes',\n",
              " 'and',\n",
              " 'reduces',\n",
              " 'mortality',\n",
              " 'rates',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bwe_0LgOSYau",
        "outputId": "c419626f-739f-4891-af1a-efebab105b89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Patients',\n",
              " 'suffering',\n",
              " 'diabetes',\n",
              " 'mellitus',\n",
              " 'require',\n",
              " 'continuous',\n",
              " 'monitoring',\n",
              " 'blood',\n",
              " 'glucose',\n",
              " 'levels',\n",
              " '.',\n",
              " 'Medications',\n",
              " 'administered',\n",
              " 'reduce',\n",
              " 'complications',\n",
              " 'neuropathy',\n",
              " 'cardiovascular',\n",
              " 'diseases',\n",
              " '.',\n",
              " 'Early',\n",
              " 'diagnosis',\n",
              " 'improves',\n",
              " 'treatment',\n",
              " 'outcomes',\n",
              " 'reduces',\n",
              " 'mortality',\n",
              " 'rates',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Stemming"
      ],
      "metadata": {
        "id": "qaH1dC_qT5Tq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(Medical)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTddR1DNSfmS",
        "outputId": "7370ec49-7ede-45f7-83e8-34467097ce56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['patient',\n",
              " 'suffer',\n",
              " 'from',\n",
              " 'diabet',\n",
              " 'mellitu',\n",
              " 'requir',\n",
              " 'continu',\n",
              " 'monitor',\n",
              " 'of',\n",
              " 'blood',\n",
              " 'glucos',\n",
              " 'level',\n",
              " '.',\n",
              " 'medic',\n",
              " 'are',\n",
              " 'administ',\n",
              " 'to',\n",
              " 'reduc',\n",
              " 'complic',\n",
              " 'such',\n",
              " 'as',\n",
              " 'neuropathi',\n",
              " 'and',\n",
              " 'cardiovascular',\n",
              " 'diseas',\n",
              " '.',\n",
              " 'earli',\n",
              " 'diagnosi',\n",
              " 'improv',\n",
              " 'treatment',\n",
              " 'outcom',\n",
              " 'and',\n",
              " 'reduc',\n",
              " 'mortal',\n",
              " 'rate',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SnowballStemmer"
      ],
      "metadata": {
        "id": "Dl5aRd1pYo72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = word_tokenize(Medical)\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOUkz9lbS7G_",
        "outputId": "3ab44c03-021b-4b6f-a4df-2e230df09e0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patients ---> patient\n",
            "suffering ---> suffer\n",
            "from ---> from\n",
            "diabetes ---> diabet\n",
            "mellitus ---> mellitus\n",
            "require ---> requir\n",
            "continuous ---> continu\n",
            "monitoring ---> monitor\n",
            "of ---> of\n",
            "blood ---> blood\n",
            "glucose ---> glucos\n",
            "levels ---> level\n",
            ". ---> .\n",
            "Medications ---> medic\n",
            "are ---> are\n",
            "administered ---> administ\n",
            "to ---> to\n",
            "reduce ---> reduc\n",
            "complications ---> complic\n",
            "such ---> such\n",
            "as ---> as\n",
            "neuropathy ---> neuropathi\n",
            "and ---> and\n",
            "cardiovascular ---> cardiovascular\n",
            "diseases ---> diseas\n",
            ". ---> .\n",
            "Early ---> earli\n",
            "diagnosis ---> diagnosi\n",
            "improves ---> improv\n",
            "treatment ---> treatment\n",
            "outcomes ---> outcom\n",
            "and ---> and\n",
            "reduces ---> reduc\n",
            "mortality ---> mortal\n",
            "rates ---> rate\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LancasterStemmer"
      ],
      "metadata": {
        "id": "ih4DT9NbWrAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(Medical)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRZVhwovWfK1",
        "outputId": "326e4f63-1e4b-4a2a-b773-b2c7a5da2d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patients ---> paty\n",
            "suffering ---> suff\n",
            "from ---> from\n",
            "diabetes ---> diabet\n",
            "mellitus ---> mellit\n",
            "require ---> requir\n",
            "continuous ---> continu\n",
            "monitoring ---> monit\n",
            "of ---> of\n",
            "blood ---> blood\n",
            "glucose ---> glucos\n",
            "levels ---> level\n",
            ". ---> .\n",
            "Medications ---> med\n",
            "are ---> ar\n",
            "administered ---> admin\n",
            "to ---> to\n",
            "reduce ---> reduc\n",
            "complications ---> comply\n",
            "such ---> such\n",
            "as ---> as\n",
            "neuropathy ---> neuropathy\n",
            "and ---> and\n",
            "cardiovascular ---> cardiovascul\n",
            "diseases ---> diseas\n",
            ". ---> .\n",
            "Early ---> ear\n",
            "diagnosis ---> diagnos\n",
            "improves ---> improv\n",
            "treatment ---> tre\n",
            "outcomes ---> outcom\n",
            "and ---> and\n",
            "reduces ---> reduc\n",
            "mortality ---> mort\n",
            "rates ---> rat\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lemmatization"
      ],
      "metadata": {
        "id": "NgOKs5oYUFsH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(Medical)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-DUYaKhUG8T",
        "outputId": "433eb13a-84b8-4705-e655-1e87c9476135"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patients ---> Patients\n",
            "suffering ---> suffering\n",
            "from ---> from\n",
            "diabetes ---> diabetes\n",
            "mellitus ---> mellitus\n",
            "require ---> require\n",
            "continuous ---> continuous\n",
            "monitoring ---> monitoring\n",
            "of ---> of\n",
            "blood ---> blood\n",
            "glucose ---> glucose\n",
            "levels ---> level\n",
            ". ---> .\n",
            "Medications ---> Medications\n",
            "are ---> are\n",
            "administered ---> administered\n",
            "to ---> to\n",
            "reduce ---> reduce\n",
            "complications ---> complication\n",
            "such ---> such\n",
            "as ---> a\n",
            "neuropathy ---> neuropathy\n",
            "and ---> and\n",
            "cardiovascular ---> cardiovascular\n",
            "diseases ---> disease\n",
            ". ---> .\n",
            "Early ---> Early\n",
            "diagnosis ---> diagnosis\n",
            "improves ---> improves\n",
            "treatment ---> treatment\n",
            "outcomes ---> outcome\n",
            "and ---> and\n",
            "reduces ---> reduces\n",
            "mortality ---> mortality\n",
            "rates ---> rate\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparison"
      ],
      "metadata": {
        "id": "R18P84L8UgLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer, WordNetLemmatizer\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "snowball = SnowballStemmer(language='english')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\n",
        "print(\"{0:20}{1:20}{2:20}{3:30}{4:40}\".format(\"Word\",\"Porter Stemmer\",\"Snowball Stemmer\",\"Lancaster Stemmer\",'WordNetLemmatizer'))\n",
        "for word in word_list:\n",
        "  print(\"{0:20}{1:20}{2:20}{3:30}{4:40}\".format(word,porter.stem(word),snowball.stem(word),lancaster.stem(word),lemmatizer.lemmatize(word)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b-hiPl0UhzA",
        "outputId": "6b7a8a0d-ba2a-42ee-8156-2461f47fcedd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Snowball Stemmer    Lancaster Stemmer             Regexp Stemmer                          \n",
            "friend              friend              friend              friend                        friend                                  \n",
            "friendship          friendship          friendship          friend                        friendship                              \n",
            "friends             friend              friend              friend                        friend                                  \n",
            "friendships         friendship          friendship          friend                        friendship                              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For SR University Text"
      ],
      "metadata": {
        "id": "qMAQ_mnF6SwG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SRUniversity=\"\"\"The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.\n",
        "It is in 150 acres, with both separate hostel facilities for boys and girls.\n",
        "There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.\"\"\""
      ],
      "metadata": {
        "id": "jQkNjjXX6YqG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(SRUniversity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hby09uEX6cBK",
        "outputId": "5b13afd2-c3f8-4713-863a-7b3c10e5c4ca"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'is',\n",
              " 'located',\n",
              " 'in',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'of',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'in',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'for',\n",
              " 'boys',\n",
              " 'and',\n",
              " 'girls',\n",
              " '.',\n",
              " 'There',\n",
              " 'is',\n",
              " 'a',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'library',\n",
              " 'along',\n",
              " 'with',\n",
              " 'Indias',\n",
              " 'largest',\n",
              " 'Technology',\n",
              " 'Business',\n",
              " 'Incubator',\n",
              " '(',\n",
              " 'TBI',\n",
              " ')',\n",
              " 'in',\n",
              " 'tier',\n",
              " '2',\n",
              " 'cities',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(SRUniversity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JKX04Vl6vh6",
        "outputId": "c01c0d6f-5bdb-4253-c4cc-b43a79ad930e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The SR University campus is located in Ananthasagar village of Hasanparthy Mandal in Warangal, Telangana, India.',\n",
              " 'It is in 150 acres, with both separate hostel facilities for boys and girls.',\n",
              " 'There is a huge central library along with Indias largest Technology Business Incubator (TBI) in tier 2 cities.']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6jUviaS6zTU",
        "outputId": "e71a2a0a-395a-44de-f536-31b7080aa28f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize(SRUniversity)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0jEjbvf63bk",
        "outputId": "73257da9-2e4b-4539-e567-7a971e80008e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'is',\n",
              " 'located',\n",
              " 'in',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'of',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'in',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " 'It',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'for',\n",
              " 'boys',\n",
              " 'and',\n",
              " 'girls',\n",
              " '.',\n",
              " 'There',\n",
              " 'is',\n",
              " 'a',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'library',\n",
              " 'along',\n",
              " 'with',\n",
              " 'Indias',\n",
              " 'largest',\n",
              " 'Technology',\n",
              " 'Business',\n",
              " 'Incubator',\n",
              " '(',\n",
              " 'TBI',\n",
              " ')',\n",
              " 'in',\n",
              " 'tier',\n",
              " '2',\n",
              " 'cities',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kI2Clfqj68Jm",
        "outputId": "057bdd98-813c-4a58-b1fb-0de392707d96"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SR',\n",
              " 'University',\n",
              " 'campus',\n",
              " 'located',\n",
              " 'Ananthasagar',\n",
              " 'village',\n",
              " 'Hasanparthy',\n",
              " 'Mandal',\n",
              " 'Warangal',\n",
              " ',',\n",
              " 'Telangana',\n",
              " ',',\n",
              " 'India',\n",
              " '.',\n",
              " '150',\n",
              " 'acres',\n",
              " ',',\n",
              " 'separate',\n",
              " 'hostel',\n",
              " 'facilities',\n",
              " 'boys',\n",
              " 'girls',\n",
              " '.',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'library',\n",
              " 'along',\n",
              " 'Indias',\n",
              " 'largest',\n",
              " 'Technology',\n",
              " 'Business',\n",
              " 'Incubator',\n",
              " '(',\n",
              " 'TBI',\n",
              " ')',\n",
              " 'tier',\n",
              " '2',\n",
              " 'cities',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ktoqr6qg7Aej",
        "outputId": "8faecdae-a04a-42bb-a241-3fb6264c81e9"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'sr',\n",
              " 'univers',\n",
              " 'campu',\n",
              " 'is',\n",
              " 'locat',\n",
              " 'in',\n",
              " 'ananthasagar',\n",
              " 'villag',\n",
              " 'of',\n",
              " 'hasanparthi',\n",
              " 'mandal',\n",
              " 'in',\n",
              " 'warang',\n",
              " ',',\n",
              " 'telangana',\n",
              " ',',\n",
              " 'india',\n",
              " '.',\n",
              " 'it',\n",
              " 'is',\n",
              " 'in',\n",
              " '150',\n",
              " 'acr',\n",
              " ',',\n",
              " 'with',\n",
              " 'both',\n",
              " 'separ',\n",
              " 'hostel',\n",
              " 'facil',\n",
              " 'for',\n",
              " 'boy',\n",
              " 'and',\n",
              " 'girl',\n",
              " '.',\n",
              " 'there',\n",
              " 'is',\n",
              " 'a',\n",
              " 'huge',\n",
              " 'central',\n",
              " 'librari',\n",
              " 'along',\n",
              " 'with',\n",
              " 'india',\n",
              " 'largest',\n",
              " 'technolog',\n",
              " 'busi',\n",
              " 'incub',\n",
              " '(',\n",
              " 'tbi',\n",
              " ')',\n",
              " 'in',\n",
              " 'tier',\n",
              " '2',\n",
              " 'citi',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5pIchAjS7CLM",
        "outputId": "424ab488-a4e6-4ab9-8599-dd2af18def48"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "SR ---> sr\n",
            "University ---> univers\n",
            "campus ---> campus\n",
            "is ---> is\n",
            "located ---> locat\n",
            "in ---> in\n",
            "Ananthasagar ---> ananthasagar\n",
            "village ---> villag\n",
            "of ---> of\n",
            "Hasanparthy ---> hasanparthi\n",
            "Mandal ---> mandal\n",
            "in ---> in\n",
            "Warangal ---> warang\n",
            ", ---> ,\n",
            "Telangana ---> telangana\n",
            ", ---> ,\n",
            "India ---> india\n",
            ". ---> .\n",
            "It ---> it\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acr\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> separ\n",
            "hostel ---> hostel\n",
            "facilities ---> facil\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> there\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> huge\n",
            "central ---> central\n",
            "library ---> librari\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> india\n",
            "largest ---> largest\n",
            "Technology ---> technolog\n",
            "Business ---> busi\n",
            "Incubator ---> incub\n",
            "( ---> (\n",
            "TBI ---> tbi\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> citi\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dL_FI1V7IIN",
        "outputId": "ac783a6a-4c49-4a5c-f64f-517ae113ac8b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "SR ---> sr\n",
            "University ---> univers\n",
            "campus ---> camp\n",
            "is ---> is\n",
            "located ---> loc\n",
            "in ---> in\n",
            "Ananthasagar ---> ananthasag\n",
            "village ---> vil\n",
            "of ---> of\n",
            "Hasanparthy ---> hasanparthy\n",
            "Mandal ---> mand\n",
            "in ---> in\n",
            "Warangal ---> warang\n",
            ", ---> ,\n",
            "Telangana ---> telangan\n",
            ", ---> ,\n",
            "India ---> ind\n",
            ". ---> .\n",
            "It ---> it\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acr\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> sep\n",
            "hostel ---> hostel\n",
            "facilities ---> facil\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> ther\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> hug\n",
            "central ---> cent\n",
            "library ---> libr\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> india\n",
            "largest ---> largest\n",
            "Technology ---> technolog\n",
            "Business ---> busy\n",
            "Incubator ---> incub\n",
            "( ---> (\n",
            "TBI ---> tbi\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> city\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "regexp = RegexpStemmer('ing|e', min=4)\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YFJnRzp7PTs",
        "outputId": "c4f1a144-652e-4d08-c6b1-6d6c77ea1a17"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> the\n",
            "SR ---> sr\n",
            "University ---> univers\n",
            "campus ---> camp\n",
            "is ---> is\n",
            "located ---> loc\n",
            "in ---> in\n",
            "Ananthasagar ---> ananthasag\n",
            "village ---> vil\n",
            "of ---> of\n",
            "Hasanparthy ---> hasanparthy\n",
            "Mandal ---> mand\n",
            "in ---> in\n",
            "Warangal ---> warang\n",
            ", ---> ,\n",
            "Telangana ---> telangan\n",
            ", ---> ,\n",
            "India ---> ind\n",
            ". ---> .\n",
            "It ---> it\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acr\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> sep\n",
            "hostel ---> hostel\n",
            "facilities ---> facil\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> ther\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> hug\n",
            "central ---> cent\n",
            "library ---> libr\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> india\n",
            "largest ---> largest\n",
            "Technology ---> technolog\n",
            "Business ---> busy\n",
            "Incubator ---> incub\n",
            "( ---> (\n",
            "TBI ---> tbi\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> city\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(SRUniversity)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0BfiuiQ7XSb",
        "outputId": "283909db-7c98-4046-c0bf-aa3a8468e9c2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ---> The\n",
            "SR ---> SR\n",
            "University ---> University\n",
            "campus ---> campus\n",
            "is ---> is\n",
            "located ---> located\n",
            "in ---> in\n",
            "Ananthasagar ---> Ananthasagar\n",
            "village ---> village\n",
            "of ---> of\n",
            "Hasanparthy ---> Hasanparthy\n",
            "Mandal ---> Mandal\n",
            "in ---> in\n",
            "Warangal ---> Warangal\n",
            ", ---> ,\n",
            "Telangana ---> Telangana\n",
            ", ---> ,\n",
            "India ---> India\n",
            ". ---> .\n",
            "It ---> It\n",
            "is ---> is\n",
            "in ---> in\n",
            "150 ---> 150\n",
            "acres ---> acre\n",
            ", ---> ,\n",
            "with ---> with\n",
            "both ---> both\n",
            "separate ---> separate\n",
            "hostel ---> hostel\n",
            "facilities ---> facility\n",
            "for ---> for\n",
            "boys ---> boy\n",
            "and ---> and\n",
            "girls ---> girl\n",
            ". ---> .\n",
            "There ---> There\n",
            "is ---> is\n",
            "a ---> a\n",
            "huge ---> huge\n",
            "central ---> central\n",
            "library ---> library\n",
            "along ---> along\n",
            "with ---> with\n",
            "Indias ---> Indias\n",
            "largest ---> largest\n",
            "Technology ---> Technology\n",
            "Business ---> Business\n",
            "Incubator ---> Incubator\n",
            "( ---> (\n",
            "TBI ---> TBI\n",
            ") ---> )\n",
            "in ---> in\n",
            "tier ---> tier\n",
            "2 ---> 2\n",
            "cities ---> city\n",
            ". ---> .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "zvCnF4ln7mzq",
        "outputId": "0b398ee3-d726-41ee-bd52-db95d09fd902"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'worst'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer.lemmatize(\"worst\", pos=\"a\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mrhArPRG7qG8",
        "outputId": "f85b5829-0593-43b0-cad3-0bf1bdefc21e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bad'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer, SnowballStemmer, LancasterStemmer, RegexpStemmer, WordNetLemmatizer\n",
        "porter = PorterStemmer()\n",
        "lancaster = LancasterStemmer()\n",
        "snowball = SnowballStemmer(language='english')\n",
        "regexp = RegexpStemmer('ing|e', min=4)\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "word_list = [\"friend\", \"friendship\", \"friends\", \"friendships\"]\n",
        "print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(\"Word\",\"Porter Stemmer\",\"Snowball Stemmer\",\"Lancaster Stemmer\",'Regexp Stemmer','WordNetLemmatizer'))\n",
        "for word in word_list:\n",
        "    print(\"{0:20}{1:20}{2:20}{3:30}{4:40}{5:50}\".format(word,porter.stem(word),snowball.stem(word),lancaster.stem(word),regexp.stem(word),lemmatizer.lemmatize(word)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv7J85lR7vqy",
        "outputId": "85c10e2e-4edb-4b09-c91d-8d70182ea42b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word                Porter Stemmer      Snowball Stemmer    Lancaster Stemmer             Regexp Stemmer                          WordNetLemmatizer                                 \n",
            "friend              friend              friend              friend                        frind                                   friend                                            \n",
            "friendship          friendship          friendship          friend                        frindship                               friendship                                        \n",
            "friends             friend              friend              friend                        frinds                                  friend                                            \n",
            "friendships         friendship          friendship          friend                        frindships                              friendship                                        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "preprocessing output of \"NLP models are transforming the world rapidly!\""
      ],
      "metadata": {
        "id": "77HUjMZu9oae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt=\"NLP models are transforming the world rapidly!\""
      ],
      "metadata": {
        "id": "XWkcl95s71Se"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "word_tokenize(txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3Mh2BMe9G2f",
        "outputId": "0bf2aa75-535e-4489-bc7e-62c912332bca"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'models', 'are', 'transforming', 'the', 'world', 'rapidly', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "sent_tokenize(txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_xhhBSF9RFs",
        "outputId": "5aaf6d07-4206-4ac9-f9d2-208a534179d3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP models are transforming the world rapidly!']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgXkMkBb9UOG",
        "outputId": "1a27dc8a-aabf-4361-b28f-2d6ec1d109dc"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words_in_quote = word_tokenize(txt)\n",
        "words_in_quote"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8YMUwLm9exU",
        "outputId": "1dd5b9c8-b35c-4e1c-e7d4-2d6a6a7b5bca"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'models', 'are', 'transforming', 'the', 'world', 'rapidly', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_list = []\n",
        "for word in words_in_quote:\n",
        "  if word.casefold() not in stop_words:\n",
        "    filtered_list.append(word)\n",
        "filtered_list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7ZwPEr-9lI3",
        "outputId": "3eb84b9d-38ac-407d-bfd8-4d7ba2748868"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['NLP', 'models', 'transforming', 'world', 'rapidly', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stemmer = PorterStemmer()\n",
        "words = word_tokenize(txt)\n",
        "stemmed_words = [stemmer.stem(word) for word in words]\n",
        "stemmed_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfMXie4b9pgi",
        "outputId": "2387368d-cc65-4410-f4bf-652b3e19533a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nlp', 'model', 'are', 'transform', 'the', 'world', 'rapidli', '!']"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')\n",
        "words = word_tokenize(txt)\n",
        "for word in words:\n",
        "    print(word,\"--->\",snowball.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdP2ICma9v_g",
        "outputId": "4ea217bb-918f-4a1c-c7e7-e9a503540fd3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> nlp\n",
            "models ---> model\n",
            "are ---> are\n",
            "transforming ---> transform\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapid\n",
            "! ---> !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import LancasterStemmer\n",
        "Lanc = LancasterStemmer()\n",
        "words = word_tokenize(txt)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dOaqTXOV9z3w",
        "outputId": "d5bddff3-33fb-44eb-e458-f79b7239f873"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> nlp\n",
            "models ---> model\n",
            "are ---> ar\n",
            "transforming ---> transform\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapid\n",
            "! ---> !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import RegexpStemmer\n",
        "regexp = RegexpStemmer('ing|e', min=4)\n",
        "words = word_tokenize(txt)\n",
        "for word in words:\n",
        "    print(word,\"--->\",Lanc.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPi-KKXr94Df",
        "outputId": "c5e5b869-3c27-4826-b2e7-b7404f5fbeb8"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> nlp\n",
            "models ---> model\n",
            "are ---> ar\n",
            "transforming ---> transform\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapid\n",
            "! ---> !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('omw-1.4')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "words = word_tokenize(txt)\n",
        "for word in words:\n",
        "    print(word,\"--->\",lemmatizer.lemmatize(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8Zy9tMT-BkN",
        "outputId": "4815382d-66c4-4468-bb38-bd5929d238a5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP ---> NLP\n",
            "models ---> model\n",
            "are ---> are\n",
            "transforming ---> transforming\n",
            "the ---> the\n",
            "world ---> world\n",
            "rapidly ---> rapidly\n",
            "! ---> !\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        }
      ]
    }
  ]
}