{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPu21ZlKhpPqmg6vegVxX69",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vengalagagan/NLP/blob/main/2403A52222_NLP_Assignmnet_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Gensim Import Libraries**"
      ],
      "metadata": {
        "id": "LXYyUCF4OomD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pXc7xWv4POaK",
        "outputId": "b7b3941e-367f-4b37-ecdc-677ce5615130"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.4.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "f17ypzayOGpF"
      },
      "outputs": [],
      "source": [
        "# gensim is used to load and work with pre-trained word embedding models\n",
        "# It provides Word2Vec, GloVe, FastText implementations\n",
        "import gensim\n",
        "\n",
        "# KeyedVectors is specifically used to load pre-trained word embeddings\n",
        "# without loading the full training model\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# numpy is used for numerical operations on vectors\n",
        "# Word embeddings are stored as numerical arrays\n",
        "import numpy as np\n",
        "\n",
        "# sklearn.metrics.pairwise is used to calculate similarity between vectors\n",
        "# cosine_similarity helps measure semantic similarity between words\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# matplotlib is used to visualize word embeddings in 2D space\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Word2Vec and find numerical vector representation of words**"
      ],
      "metadata": {
        "id": "HaCjZC6RP4lS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "# Load pre-trained Word2Vec model (may take time on first download)\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# Print vocabulary size\n",
        "print(\"Vocabulary Size:\", len(model.key_to_index))\n",
        "\n",
        "# Display vector for a sample word\n",
        "word = \"king\"\n",
        "vector = model[word]\n",
        "\n",
        "print(\"\\nWord:\", word)\n",
        "print(\"Vector length:\", len(vector))\n",
        "print(\"First 10 values of the vector:\\n\", vector[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5L7euoPPAJL",
        "outputId": "5d8fbac1-7779-4022-9cec-73f749b3eff5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "Vocabulary Size: 3000000\n",
            "\n",
            "Word: king\n",
            "Vector length: 300\n",
            "First 10 values of the vector:\n",
            " [ 0.12597656  0.02978516  0.00860596  0.13964844 -0.02563477 -0.03613281\n",
            "  0.11181641 -0.19824219  0.05126953  0.36328125]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Glove and find numerical vector representation of words**"
      ],
      "metadata": {
        "id": "Sop_aq4lRexj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load GloVe embeddings (100-dimensional)\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "# Print vocabulary size\n",
        "print(\"Vocabulary Size:\", len(model.key_to_index))\n",
        "\n",
        "# Display vector for a sample word\n",
        "word = \"king\"\n",
        "vector = model[word]\n",
        "\n",
        "print(\"\\nWord:\", word)\n",
        "print(\"Vector length:\", len(vector))\n",
        "print(\"First 10 values of the vector:\\n\", vector[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzL0VxTcP965",
        "outputId": "626b6734-6154-4607-fe4f-f6332bec70d7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "Vocabulary Size: 400000\n",
            "\n",
            "Word: king\n",
            "Vector length: 100\n",
            "First 10 values of the vector:\n",
            " [-0.32307 -0.87616  0.21977  0.25268  0.22976  0.7388  -0.37954 -0.35307\n",
            " -0.84369 -1.1113 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3584ccf1"
      },
      "source": [
        "# **Word Similarity with Word2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a88e2606",
        "outputId": "e78ac8e7-d4c2-4e4d-acdf-e963ae69a310"
      },
      "source": [
        "# Define word pairs for similarity calculation\n",
        "word_pairs = [\n",
        "    (\"woman\", \"man\"),\n",
        "    (\"king\", \"queen\"),\n",
        "    (\"apple\", \"fruit\"),\n",
        "    (\"car\", \"automobile\"),\n",
        "    (\"doctor\", \"hospital\"),\n",
        "    (\"dog\", \"cat\"),\n",
        "    (\"happy\", \"sad\"),\n",
        "    (\"big\", \"large\"),\n",
        "    (\"run\", \"walk\"),\n",
        "    (\"house\", \"home\")\n",
        "]\n",
        "\n",
        "print(\"Word Similarity Scores (Word2Vec Google News):\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "for w1, w2 in word_pairs:\n",
        "    try:\n",
        "        similarity = model.similarity(w1, w2)\n",
        "        print(f\"{w1} - {w2} : {similarity:.4f}\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Could not find one or both words in the vocabulary for '{w1}' and '{w2}': {e}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Similarity Scores (Word2Vec Google News):\n",
            "---------------------------------------------------\n",
            "woman - man : 0.8323\n",
            "king - queen : 0.7508\n",
            "apple - fruit : 0.5359\n",
            "car - automobile : 0.6832\n",
            "doctor - hospital : 0.6901\n",
            "dog - cat : 0.8798\n",
            "happy - sad : 0.6801\n",
            "big - large : 0.7082\n",
            "run - walk : 0.6683\n",
            "house - home : 0.6720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "501b4e6c"
      },
      "source": [
        "### **Word Similarity with GloVe**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "025728d7",
        "outputId": "4b61a5ba-3234-4f00-bf3c-3431de3f2f35"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained GloVe model (100D)\n",
        "# If 'model' from the previous GloVe loading step is not available,\n",
        "# or if the kernel restarts, uncomment the line below:\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "# Define word pairs for similarity calculation\n",
        "word_pairs = [\n",
        "    (\"woman\", \"man\"),\n",
        "    (\"king\", \"queen\"),\n",
        "    (\"apple\", \"fruit\"),\n",
        "    (\"car\", \"automobile\"),\n",
        "    (\"doctor\", \"hospital\"),\n",
        "    (\"dog\", \"cat\"),\n",
        "    (\"happy\", \"sad\"),\n",
        "    (\"big\", \"large\"),\n",
        "    (\"run\", \"walk\"),\n",
        "    (\"house\", \"home\")\n",
        "]\n",
        "\n",
        "print(\"Word Similarity Scores (GloVe Wiki Gigaword):\")\n",
        "print(\"---------------------------------------------------\")\n",
        "\n",
        "for w1, w2 in word_pairs:\n",
        "    try:\n",
        "        similarity = model.similarity(w1, w2)\n",
        "        print(f\"{w1} - {w2} : {similarity:.4f}\")\n",
        "    except KeyError as e:\n",
        "        print(f\"Could not find one or both words in the vocabulary for '{w1}' and '{w2}': {e}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word Similarity Scores (GloVe Wiki Gigaword):\n",
            "---------------------------------------------------\n",
            "woman - man : 0.8323\n",
            "king - queen : 0.7508\n",
            "apple - fruit : 0.5359\n",
            "car - automobile : 0.6832\n",
            "doctor - hospital : 0.6901\n",
            "dog - cat : 0.8798\n",
            "happy - sad : 0.6801\n",
            "big - large : 0.7082\n",
            "run - walk : 0.6683\n",
            "house - home : 0.6720\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Word2Vec and complete Neighbour words**"
      ],
      "metadata": {
        "id": "1gqqZBpZREYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a list of words for which to find nearest neighbors\n",
        "chosen_words = [\"king\", \"university\", \"doctor\", \"car\", \"music\", \"java\", \"python\"]\n",
        "\n",
        "print(\"Nearest Neighbor Exploration (Word2Vec Google News):\\n\")\n",
        "\n",
        "for word in chosen_words:\n",
        "    print(f\"\\nTop similar words for '{word}':\\n\")\n",
        "    try:\n",
        "        # Find the top 5 most similar words for the current word\n",
        "        similar_words = model.most_similar(word, topn=5)\n",
        "        for similar_word, score in similar_words:\n",
        "            print(f\"{similar_word} : {score:.4f}\")\n",
        "    except KeyError:\n",
        "        print(f\"Word '{word}' not found in vocabulary.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sClpHLX7Q1c2",
        "outputId": "770fa16c-d469-488a-ade4-043e14f509fe"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nearest Neighbor Exploration (Word2Vec Google News):\n",
            "\n",
            "\n",
            "Top similar words for 'king':\n",
            "\n",
            "prince : 0.7682\n",
            "queen : 0.7508\n",
            "son : 0.7021\n",
            "brother : 0.6986\n",
            "monarch : 0.6978\n",
            "\n",
            "Top similar words for 'university':\n",
            "\n",
            "college : 0.8294\n",
            "harvard : 0.8156\n",
            "yale : 0.8114\n",
            "professor : 0.8104\n",
            "graduate : 0.7993\n",
            "\n",
            "Top similar words for 'doctor':\n",
            "\n",
            "physician : 0.7673\n",
            "nurse : 0.7522\n",
            "dr. : 0.7175\n",
            "doctors : 0.7081\n",
            "patient : 0.7074\n",
            "\n",
            "Top similar words for 'car':\n",
            "\n",
            "vehicle : 0.8631\n",
            "truck : 0.8598\n",
            "cars : 0.8372\n",
            "driver : 0.8186\n",
            "driving : 0.7813\n",
            "\n",
            "Top similar words for 'music':\n",
            "\n",
            "musical : 0.8128\n",
            "songs : 0.7978\n",
            "dance : 0.7897\n",
            "pop : 0.7863\n",
            "recording : 0.7651\n",
            "\n",
            "Top similar words for 'java':\n",
            "\n",
            "sumatra : 0.6642\n",
            "surabaya : 0.6600\n",
            "semarang : 0.6302\n",
            "sulawesi : 0.6134\n",
            "yogyakarta : 0.6033\n",
            "\n",
            "Top similar words for 'python':\n",
            "\n",
            "monty : 0.6886\n",
            "php : 0.5865\n",
            "perl : 0.5784\n",
            "cleese : 0.5447\n",
            "flipper : 0.5113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Glove and complete Neighbour words**\n"
      ],
      "metadata": {
        "id": "0MEXxgUVRO6U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Load pre-trained GloVe model (100D)\n",
        "# If 'model' from previous steps is not available or kernel restarts, uncomment below:\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "# Define a list of words for which to find nearest neighbors\n",
        "chosen_words = [\"king\", \"university\", \"doctor\", \"car\", \"music\", \"java\", \"python\"]\n",
        "\n",
        "print(\"Nearest Neighbor Exploration (GloVe Wiki Gigaword):\\n\")\n",
        "\n",
        "for word in chosen_words:\n",
        "    print(f\"\\nTop similar words for '{word}':\\n\")\n",
        "    try:\n",
        "        # Find the top 5 most similar words for the current word\n",
        "        similar_words = model.most_similar(word, topn=5)\n",
        "        for similar_word, score in similar_words:\n",
        "            print(f\"{similar_word} : {score:.4f}\")\n",
        "    except KeyError:\n",
        "        print(f\"Word '{word}' not found in vocabulary.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCcjewvcRIHh",
        "outputId": "5e14db46-8e09-4b8d-c51d-f5ad074be25c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nearest Neighbor Exploration (GloVe Wiki Gigaword):\n",
            "\n",
            "\n",
            "Top similar words for 'king':\n",
            "\n",
            "prince : 0.7682\n",
            "queen : 0.7508\n",
            "son : 0.7021\n",
            "brother : 0.6986\n",
            "monarch : 0.6978\n",
            "\n",
            "Top similar words for 'university':\n",
            "\n",
            "college : 0.8294\n",
            "harvard : 0.8156\n",
            "yale : 0.8114\n",
            "professor : 0.8104\n",
            "graduate : 0.7993\n",
            "\n",
            "Top similar words for 'doctor':\n",
            "\n",
            "physician : 0.7673\n",
            "nurse : 0.7522\n",
            "dr. : 0.7175\n",
            "doctors : 0.7081\n",
            "patient : 0.7074\n",
            "\n",
            "Top similar words for 'car':\n",
            "\n",
            "vehicle : 0.8631\n",
            "truck : 0.8598\n",
            "cars : 0.8372\n",
            "driver : 0.8186\n",
            "driving : 0.7813\n",
            "\n",
            "Top similar words for 'music':\n",
            "\n",
            "musical : 0.8128\n",
            "songs : 0.7978\n",
            "dance : 0.7897\n",
            "pop : 0.7863\n",
            "recording : 0.7651\n",
            "\n",
            "Top similar words for 'java':\n",
            "\n",
            "sumatra : 0.6642\n",
            "surabaya : 0.6600\n",
            "semarang : 0.6302\n",
            "sulawesi : 0.6134\n",
            "yogyakarta : 0.6033\n",
            "\n",
            "Top similar words for 'python':\n",
            "\n",
            "monty : 0.6886\n",
            "php : 0.5865\n",
            "perl : 0.5784\n",
            "cleese : 0.5447\n",
            "flipper : 0.5113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f02da19"
      },
      "source": [
        "# **Word Analogy with Word2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dda86e7",
        "outputId": "abd624eb-3add-4f55-9255-fee781fb50d2"
      },
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Ensure the correct Word2Vec model is loaded, if not already in the kernel state.\n",
        "# If `model` from the previous Word2Vec loading step is not available,\n",
        "# or if the kernel restarts, uncomment the line below:\n",
        "model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# Analogy 1: King - man + woman = queen\n",
        "result1 = model.most_similar(\n",
        "    positive=[\"king\", \"woman\"],\n",
        "    negative=[\"man\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "# Analogy 2: Paris - France + India = ? (Capital analogy)\n",
        "result2 = model.most_similar(\n",
        "    positive=[\"paris\", \"india\"],\n",
        "    negative=[\"france\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "# Analogy 3: Doctor - hospital + school = ? (Profession/Location analogy)\n",
        "result3 = model.most_similar(\n",
        "    positive=[\"doctor\", \"school\"],\n",
        "    negative=[\"hospital\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "print(\"\\n--- Word Analogies with Word2Vec ---\")\n",
        "\n",
        "print(\"\\nking - man + woman = ?\")\n",
        "print(result1)\n",
        "\n",
        "print(\"\\nparis - france + india = ?\")\n",
        "print(result2)\n",
        "\n",
        "print(\"\\ndoctor - hospital + school = ?\")\n",
        "print(result3)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Word Analogies with Word2Vec ---\n",
            "\n",
            "king - man + woman = ?\n",
            "[('queen', 0.7118193507194519), ('monarch', 0.6189674139022827), ('princess', 0.5902431011199951), ('crown_prince', 0.5499460697174072), ('prince', 0.5377321839332581)]\n",
            "\n",
            "paris - france + india = ?\n",
            "[('chennai', 0.5442505478858948), ('delhi', 0.5149926543235779), ('mumbai', 0.5024341344833374), ('hyderabad', 0.49932485818862915), ('gujarat', 0.48732805252075195)]\n",
            "\n",
            "doctor - hospital + school = ?\n",
            "[('guidance_counselor', 0.5969594717025757), ('teacher', 0.5755364298820496), ('eighth_grade', 0.5226408243179321), ('schoolers', 0.5168290138244629), ('elementary', 0.5085657238960266)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Load Glove and complete word analogy**"
      ],
      "metadata": {
        "id": "XfjXpyDGSoNw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# Ensure the correct GloVe model is loaded, if not already in the kernel state.\n",
        "# If `model` from the previous GloVe loading step is not available,\n",
        "# or if the kernel restarts, uncomment the line below:\n",
        "model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "# Analogy 1: King - man + woman = queen\n",
        "result1 = model.most_similar(\n",
        "    positive=[\"king\", \"woman\"],\n",
        "    negative=[\"man\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "# Analogy 2: Paris - France + India = ? (Capital analogy)\n",
        "result2 = model.most_similar(\n",
        "    positive=[\"paris\", \"india\"],\n",
        "    negative=[\"france\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "# Analogy 3: Doctor - hospital + school = ? (Profession/Location analogy)\n",
        "result3 = model.most_similar(\n",
        "    positive=[\"doctor\", \"school\"],\n",
        "    negative=[\"hospital\"],\n",
        "    topn=5\n",
        ")\n",
        "\n",
        "print(\"\\n--- Word Analogies with GloVe ---\")\n",
        "\n",
        "print(\"\\nking - man + woman = ?\")\n",
        "print(result1)\n",
        "\n",
        "print(\"\\nparis - france + india = ?\")\n",
        "print(result2)\n",
        "\n",
        "print(\"\\ndoctor - hospital + school = ?\")\n",
        "print(result3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLNAgvQGShdJ",
        "outputId": "74ed1d4d-c46b-4e5c-e405-3f6c25ce07cc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Word Analogies with GloVe ---\n",
            "\n",
            "king - man + woman = ?\n",
            "[('queen', 0.7698540687561035), ('monarch', 0.6843381524085999), ('throne', 0.6755736470222473), ('daughter', 0.6594556570053101), ('princess', 0.6520534157752991)]\n",
            "\n",
            "paris - france + india = ?\n",
            "[('delhi', 0.8654932975769043), ('mumbai', 0.7718895077705383), ('bombay', 0.7222235798835754), ('dhaka', 0.6891742944717407), ('calcutta', 0.6761991381645203)]\n",
            "\n",
            "doctor - hospital + school = ?\n",
            "[('teacher', 0.7837691307067871), ('taught', 0.7343935370445251), ('graduate', 0.7131244540214539), ('student', 0.6969646215438843), ('college', 0.6951188445091248)]\n"
          ]
        }
      ]
    }
  ]
}