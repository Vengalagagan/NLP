{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPk9lPM9Igl4/BMNyOgT4tB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vengalagagan/NLP/blob/main/2403A52222_NLP_Assignmnet_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Corpus\n"
      ],
      "metadata": {
        "id": "MT_12P_KHWxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "D1 = \"I am teaching computer science courses\"\n",
        "D2 = \"I am working as an associate professor\"\n",
        "D3 = \"I completed my bachelor's degree in JNTUH\"\n",
        "D4 = \"I received my doctorate from IIT Delhi\"\n",
        "D5 = \"I am involved in research projects\"\n",
        "D6 = \"I have published several research papers in international journals\"\n",
        "D7 = \"I supervise undergraduate and postgraduate students\"\n",
        "D8 = \"I attend academic conferences regularly\"\n",
        "D9 = \"I serve on university academic committees\"\n",
        "D10 = \"I collaborate with faculty members from other institutions\"\n"
      ],
      "metadata": {
        "id": "ipK_cgpzK7Ct"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unigram"
      ],
      "metadata": {
        "id": "nM-I3vFyN40B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9gjhmH1FT7Q",
        "outputId": "e4ffc6a8-bb6f-4222-dbe5-01ceaf554f6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unigram Count of words:\n",
            "i: 10\n",
            "am: 3\n",
            "teaching: 1\n",
            "computer: 1\n",
            "science: 1\n",
            "courses: 1\n",
            "working: 1\n",
            "as: 1\n",
            "an: 1\n",
            "associate: 1\n",
            "professor: 1\n",
            "completed: 1\n",
            "my: 2\n",
            "bachelor: 1\n",
            "s: 1\n",
            "degree: 1\n",
            "in: 3\n",
            "jntuh: 1\n",
            "received: 1\n",
            "doctorate: 1\n",
            "from: 2\n",
            "iit: 1\n",
            "delhi: 1\n",
            "involved: 1\n",
            "research: 2\n",
            "projects: 1\n",
            "have: 1\n",
            "published: 1\n",
            "several: 1\n",
            "papers: 1\n",
            "international: 1\n",
            "journals: 1\n",
            "supervise: 1\n",
            "undergraduate: 1\n",
            "and: 1\n",
            "postgraduate: 1\n",
            "students: 1\n",
            "attend: 1\n",
            "academic: 2\n",
            "conferences: 1\n",
            "regularly: 1\n",
            "serve: 1\n",
            "on: 1\n",
            "university: 1\n",
            "committees: 1\n",
            "collaborate: 1\n",
            "with: 1\n",
            "faculty: 1\n",
            "members: 1\n",
            "other: 1\n",
            "institutions: 1\n",
            "Vocabulary Size  number= 51\n"
          ]
        }
      ],
      "source": [
        "import collections\n",
        "import re\n",
        "\n",
        "# Definitions moved here for self-containment due to execution order\n",
        "D1 = \"I am teaching computer science courses\"\n",
        "D2 = \"I am working as an associate professor\"\n",
        "D3 = \"I completed my bachelor's degree in JNTUH\"\n",
        "D4 = \"I received my doctorate from IIT Delhi\"\n",
        "D5 = \"I am involved in research projects\"\n",
        "D6 = \"I have published several research papers in international journals\"\n",
        "D7 = \"I supervise undergraduate and postgraduate students\"\n",
        "D8 = \"I attend academic conferences regularly\"\n",
        "D9 = \"I serve on university academic committees\"\n",
        "D10 = \"I collaborate with faculty members from other institutions\"\n",
        "\n",
        "# Combine the text from D1, D2, D3, D4 into a list\n",
        "documents = [D1, D2, D3, D4,D5,D6,D7,D8,D9,D10]\n",
        "combined_text = \" \".join(documents)\n",
        "\n",
        "# Tokenize: remove punctuation and convert to lowercase\n",
        "words = re.findall(r'\\b\\w+\\b', combined_text.lower())\n",
        "\n",
        "# Calculate unigram counts\n",
        "unigram_counts = collections.Counter(words)\n",
        "\n",
        "# Print unigram counts\n",
        "print(\"Unigram Count of words:\")\n",
        "for word, count in unigram_counts.items():\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "# Vocabulary size\n",
        "V = len(unigram_counts)\n",
        "print(\"Vocabulary Size  number=\", V)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bigram"
      ],
      "metadata": {
        "id": "oF_aUXpTNxeM"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e084cbd",
        "outputId": "7313c3a0-79ce-4959-bb8c-3ad3162352e7"
      },
      "source": [
        "# Generate bigrams from the 'words' list\n",
        "bigrams = []\n",
        "for i in range(len(words) - 1):\n",
        "    bigrams.append((words[i], words[i+1]))\n",
        "\n",
        "# Calculate bigram counts\n",
        "bigram_counts = collections.Counter(bigrams)\n",
        "\n",
        "# Print bigram counts\n",
        "print(\"Bigram Count of words:\")\n",
        "for bigram, count in bigram_counts.items():\n",
        "    print(f\"{bigram}: {count}\")\n",
        "\n",
        "# Vocabulary size of bigrams\n",
        "V_bigram = len(bigram_counts)\n",
        "print(\"Bigram Vocabulary Size number=\", V_bigram)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigram Count of words:\n",
            "('i', 'am'): 3\n",
            "('am', 'teaching'): 1\n",
            "('teaching', 'computer'): 1\n",
            "('computer', 'science'): 1\n",
            "('science', 'courses'): 1\n",
            "('courses', 'i'): 1\n",
            "('am', 'working'): 1\n",
            "('working', 'as'): 1\n",
            "('as', 'an'): 1\n",
            "('an', 'associate'): 1\n",
            "('associate', 'professor'): 1\n",
            "('professor', 'i'): 1\n",
            "('i', 'completed'): 1\n",
            "('completed', 'my'): 1\n",
            "('my', 'bachelor'): 1\n",
            "('bachelor', 's'): 1\n",
            "('s', 'degree'): 1\n",
            "('degree', 'in'): 1\n",
            "('in', 'jntuh'): 1\n",
            "('jntuh', 'i'): 1\n",
            "('i', 'received'): 1\n",
            "('received', 'my'): 1\n",
            "('my', 'doctorate'): 1\n",
            "('doctorate', 'from'): 1\n",
            "('from', 'iit'): 1\n",
            "('iit', 'delhi'): 1\n",
            "('delhi', 'i'): 1\n",
            "('am', 'involved'): 1\n",
            "('involved', 'in'): 1\n",
            "('in', 'research'): 1\n",
            "('research', 'projects'): 1\n",
            "('projects', 'i'): 1\n",
            "('i', 'have'): 1\n",
            "('have', 'published'): 1\n",
            "('published', 'several'): 1\n",
            "('several', 'research'): 1\n",
            "('research', 'papers'): 1\n",
            "('papers', 'in'): 1\n",
            "('in', 'international'): 1\n",
            "('international', 'journals'): 1\n",
            "('journals', 'i'): 1\n",
            "('i', 'supervise'): 1\n",
            "('supervise', 'undergraduate'): 1\n",
            "('undergraduate', 'and'): 1\n",
            "('and', 'postgraduate'): 1\n",
            "('postgraduate', 'students'): 1\n",
            "('students', 'i'): 1\n",
            "('i', 'attend'): 1\n",
            "('attend', 'academic'): 1\n",
            "('academic', 'conferences'): 1\n",
            "('conferences', 'regularly'): 1\n",
            "('regularly', 'i'): 1\n",
            "('i', 'serve'): 1\n",
            "('serve', 'on'): 1\n",
            "('on', 'university'): 1\n",
            "('university', 'academic'): 1\n",
            "('academic', 'committees'): 1\n",
            "('committees', 'i'): 1\n",
            "('i', 'collaborate'): 1\n",
            "('collaborate', 'with'): 1\n",
            "('with', 'faculty'): 1\n",
            "('faculty', 'members'): 1\n",
            "('members', 'from'): 1\n",
            "('from', 'other'): 1\n",
            "('other', 'institutions'): 1\n",
            "Bigram Vocabulary Size number= 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e85728a"
      },
      "source": [
        "Trigram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c99099f5",
        "outputId": "db7cc0cf-64c0-4f5c-bceb-ec161a7bae0f"
      },
      "source": [
        "import collections\n",
        "\n",
        "# Generate trigrams from the 'words' list\n",
        "trigrams = []\n",
        "for i in range(len(words) - 2):\n",
        "    trigrams.append((words[i], words[i+1], words[i+2]))\n",
        "\n",
        "# Calculate trigram counts\n",
        "trigram_counts = collections.Counter(trigrams)\n",
        "\n",
        "# Print trigram counts\n",
        "print(\"Trigram Count of words:\")\n",
        "for trigram, count in trigram_counts.items():\n",
        "    print(f\"{trigram}: {count}\")\n",
        "\n",
        "# Vocabulary size of trigrams\n",
        "V_trigram = len(trigram_counts)\n",
        "print(\"Trigram Vocabulary Size number=\", V_trigram)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trigram Count of words:\n",
            "('i', 'am', 'teaching'): 1\n",
            "('am', 'teaching', 'computer'): 1\n",
            "('teaching', 'computer', 'science'): 1\n",
            "('computer', 'science', 'courses'): 1\n",
            "('science', 'courses', 'i'): 1\n",
            "('courses', 'i', 'am'): 1\n",
            "('i', 'am', 'working'): 1\n",
            "('am', 'working', 'as'): 1\n",
            "('working', 'as', 'an'): 1\n",
            "('as', 'an', 'associate'): 1\n",
            "('an', 'associate', 'professor'): 1\n",
            "('associate', 'professor', 'i'): 1\n",
            "('professor', 'i', 'completed'): 1\n",
            "('i', 'completed', 'my'): 1\n",
            "('completed', 'my', 'bachelor'): 1\n",
            "('my', 'bachelor', 's'): 1\n",
            "('bachelor', 's', 'degree'): 1\n",
            "('s', 'degree', 'in'): 1\n",
            "('degree', 'in', 'jntuh'): 1\n",
            "('in', 'jntuh', 'i'): 1\n",
            "('jntuh', 'i', 'received'): 1\n",
            "('i', 'received', 'my'): 1\n",
            "('received', 'my', 'doctorate'): 1\n",
            "('my', 'doctorate', 'from'): 1\n",
            "('doctorate', 'from', 'iit'): 1\n",
            "('from', 'iit', 'delhi'): 1\n",
            "('iit', 'delhi', 'i'): 1\n",
            "('delhi', 'i', 'am'): 1\n",
            "('i', 'am', 'involved'): 1\n",
            "('am', 'involved', 'in'): 1\n",
            "('involved', 'in', 'research'): 1\n",
            "('in', 'research', 'projects'): 1\n",
            "('research', 'projects', 'i'): 1\n",
            "('projects', 'i', 'have'): 1\n",
            "('i', 'have', 'published'): 1\n",
            "('have', 'published', 'several'): 1\n",
            "('published', 'several', 'research'): 1\n",
            "('several', 'research', 'papers'): 1\n",
            "('research', 'papers', 'in'): 1\n",
            "('papers', 'in', 'international'): 1\n",
            "('in', 'international', 'journals'): 1\n",
            "('international', 'journals', 'i'): 1\n",
            "('journals', 'i', 'supervise'): 1\n",
            "('i', 'supervise', 'undergraduate'): 1\n",
            "('supervise', 'undergraduate', 'and'): 1\n",
            "('undergraduate', 'and', 'postgraduate'): 1\n",
            "('and', 'postgraduate', 'students'): 1\n",
            "('postgraduate', 'students', 'i'): 1\n",
            "('students', 'i', 'attend'): 1\n",
            "('i', 'attend', 'academic'): 1\n",
            "('attend', 'academic', 'conferences'): 1\n",
            "('academic', 'conferences', 'regularly'): 1\n",
            "('conferences', 'regularly', 'i'): 1\n",
            "('regularly', 'i', 'serve'): 1\n",
            "('i', 'serve', 'on'): 1\n",
            "('serve', 'on', 'university'): 1\n",
            "('on', 'university', 'academic'): 1\n",
            "('university', 'academic', 'committees'): 1\n",
            "('academic', 'committees', 'i'): 1\n",
            "('committees', 'i', 'collaborate'): 1\n",
            "('i', 'collaborate', 'with'): 1\n",
            "('collaborate', 'with', 'faculty'): 1\n",
            "('with', 'faculty', 'members'): 1\n",
            "('faculty', 'members', 'from'): 1\n",
            "('members', 'from', 'other'): 1\n",
            "('from', 'other', 'institutions'): 1\n",
            "Trigram Vocabulary Size number= 66\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram"
      ],
      "metadata": {
        "id": "BRNVBMEDOlAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for Next Word Prediction Using Bi-Gram Counts\n",
        "def predict_next_word_bigram(current_word, bigram_counts):\n",
        "    possible_next_words = collections.defaultdict(int)\n",
        "\n",
        "    # Find all bigrams starting with the current_word\n",
        "    for (word1, word2), count in bigram_counts.items():\n",
        "        if word1 == current_word:\n",
        "            possible_next_words[word2] = count\n",
        "\n",
        "    if not possible_next_words:\n",
        "        return \"No prediction available for this word based on existing bigrams.\"\n",
        "\n",
        "    # Find the next word with the highest count\n",
        "    predicted_word = max(possible_next_words, key=possible_next_words.get)\n",
        "    return predicted_word\n",
        "\n",
        "# Example Usage:\n",
        "# Make sure 'bigram_counts' is defined from previous steps\n",
        "if 'bigram_counts' in locals():\n",
        "    word_to_predict = \"am\"\n",
        "    prediction = predict_next_word_bigram(word_to_predict, bigram_counts)\n",
        "    print(f\"Given the word '{word_to_predict}', the predicted next word is: '{prediction}'\")\n",
        "\n",
        "    word_to_predict_2 = \"computer\"\n",
        "    prediction_2 = predict_next_word_bigram(word_to_predict_2, bigram_counts)\n",
        "    print(f\"Given the word '{word_to_predict_2}', the predicted next word is: '{prediction_2}'\")\n",
        "\n",
        "    word_to_predict_3 = \"nonexistentword\"\n",
        "    prediction_3 = predict_next_word_bigram(word_to_predict_3, bigram_counts)\n",
        "    print(f\"Given the word '{word_to_predict_3}', the predicted next word is: '{prediction_3}'\")\n",
        "else:\n",
        "    print(\"Error: bigram_counts not found. Please ensure the bigram cell has been executed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U03am1-RM9fy",
        "outputId": "b429d011-654c-437a-84a1-4c56e5b8c4ee"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Given the word 'am', the predicted next word is: 'teaching'\n",
            "Given the word 'computer', the predicted next word is: 'science'\n",
            "Given the word 'nonexistentword', the predicted next word is: 'No prediction available for this word based on existing bigrams.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=input(\"enter text\").lower()\n",
        "words_from_input = text.split()\n",
        "\n",
        "if len(words_from_input) >= 1:\n",
        "    # For bigram prediction, we only need the last word from the input sequence\n",
        "    current_word_for_prediction = words_from_input[-1]\n",
        "    # Call the bigram prediction function with the single current word and bigram counts\n",
        "    next_word1 = predict_next_word_bigram(current_word_for_prediction, bigram_counts)\n",
        "    print(f\"Given sequence: '{text}', predicted next word: '{next_word1}'\")\n",
        "else:\n",
        "    print(f\"Given sequence: '{text}', please enter at least one word for bigram prediction.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YzufHkuSDoA",
        "outputId": "afb5ccc6-fad9-43e2-e410-8e05e9fc24b0"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti am\n",
            "Given sequence: 'i am', predicted next word: 'teaching'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Tri-Gram"
      ],
      "metadata": {
        "id": "g2ANeg5mPScs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Function for Next Word Prediction Using Tri-Gram Counts\n",
        "def predict_next_word_trigram(current_word_1, current_word_2, trigram_counts):\n",
        "    possible_next_words = collections.defaultdict(int)\n",
        "\n",
        "    # Find all trigrams starting with the current_word_1 and current_word_2\n",
        "    for (word1, word2, word3), count in trigram_counts.items():\n",
        "        if word1 == current_word_1 and word2 == current_word_2:\n",
        "            possible_next_words[word3] = count\n",
        "\n",
        "    if not possible_next_words:\n",
        "        return \"No prediction available for these two words based on existing trigrams.\"\n",
        "\n",
        "    # Find the next word with the highest count\n",
        "    predicted_word = max(possible_next_words, key=possible_next_words.get)\n",
        "    return predicted_word\n",
        "\n",
        "# Example Usage:\n",
        "# Make sure 'trigram_counts' is defined from previous steps\n",
        "if 'trigram_counts' in locals():\n",
        "    print(\"\\n--- Trigram Next Word Prediction ---\")\n",
        "\n",
        "    # Example 1: Predict after ('i', 'am')\n",
        "    word_to_predict_1a = \"i\"\n",
        "    word_to_predict_1b = \"am\"\n",
        "    prediction_1 = predict_next_word_trigram(word_to_predict_1a, word_to_predict_1b, trigram_counts)\n",
        "    print(f\"Given the words '{word_to_predict_1a}' and '{word_to_predict_1b}', the predicted next word is: '{prediction_1}'\")\n",
        "\n",
        "    # Example 2: Predict after ('computer', 'science')\n",
        "    word_to_predict_2a = \"computer\"\n",
        "    word_to_predict_2b = \"science\"\n",
        "    prediction_2 = predict_next_word_trigram(word_to_predict_2a, word_to_predict_2b, trigram_counts)\n",
        "    print(f\"Given the words '{word_to_predict_2a}' and '{word_to_predict_2b}', the predicted next word is: '{prediction_2}'\")\n",
        "\n",
        "    # Example 3: Predict after non-existent bigram\n",
        "    word_to_predict_3a = \"nonexistent\"\n",
        "    word_to_predict_3b = \"words\"\n",
        "    prediction_3 = predict_next_word_trigram(word_to_predict_3a, word_to_predict_3b, trigram_counts)\n",
        "    print(f\"Given the words '{word_to_predict_3a}' and '{word_to_predict_3b}', the predicted next word is: '{prediction_3}'\")\n",
        "else:\n",
        "    print(\"Error: trigram_counts not found. Please ensure the trigram cell has been executed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Dp4WA8kPKIr",
        "outputId": "2a037eb7-230f-4f24-9450-d8dad8222e8b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Trigram Next Word Prediction ---\n",
            "Given the words 'i' and 'am', the predicted next word is: 'teaching'\n",
            "Given the words 'computer' and 'science', the predicted next word is: 'courses'\n",
            "Given the words 'nonexistent' and 'words', the predicted next word is: 'No prediction available for these two words based on existing trigrams.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=input(\"enter text\").lower()\n",
        "words_from_input = text.split()\n",
        "\n",
        "if len(words_from_input) >= 2:\n",
        "    word1, word2 = words_from_input[-2], words_from_input[-1] # Take the last two words for prediction\n",
        "    next_word1 = predict_next_word_trigram(word1, word2, trigram_counts)\n",
        "    print(f\"Given sequence: '{text}', predicted next word: '{next_word1}'\")\n",
        "elif len(words_from_input) == 1:\n",
        "    print(f\"Given sequence: '{text}', trigram prediction requires at least two words preceding.\")\n",
        "else:\n",
        "    print(f\"Given sequence: '{text}', please enter at least two words for trigram prediction.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stkdTB2ETqsG",
        "outputId": "8dda986c-89bd-41ff-f15e-37065a488a36"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti have published\n",
            "Given sequence: 'i have published', predicted next word: 'several'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram with Laplace Smoothening"
      ],
      "metadata": {
        "id": "kA0N73duUIW3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Ensure unigram_counts and V (vocabulary size) are available from previous steps\n",
        "# V = len(unigram_counts) should be calculated after all documents are processed\n",
        "\n",
        "# Function for Next Word Prediction Using Bi-Gram Counts with Laplace Smoothing\n",
        "def predict_next_word_bigram_laplace(current_word, bigram_counts, unigram_counts, vocabulary_size):\n",
        "    possible_next_words_scores = collections.defaultdict(float)\n",
        "\n",
        "    # Get count of the current word\n",
        "    count_current_word = unigram_counts.get(current_word, 0)\n",
        "\n",
        "    # If the current word itself is not in the vocabulary, we can't predict based on bigrams\n",
        "    if count_current_word == 0:\n",
        "        return \"No prediction available for this word (not in vocabulary).\"\n",
        "\n",
        "    # Calculate denominator for Laplace smoothing: Count(current_word) + V\n",
        "    denominator = count_current_word + vocabulary_size\n",
        "\n",
        "    # Iterate through all possible next words to find the one with the highest smoothed probability\n",
        "    all_words_in_vocab = list(unigram_counts.keys())\n",
        "    for next_word_candidate in all_words_in_vocab:\n",
        "        # Get count of the bigram (current_word, next_word_candidate)\n",
        "        bigram_tuple = (current_word, next_word_candidate)\n",
        "        count_bigram = bigram_counts.get(bigram_tuple, 0)\n",
        "\n",
        "        # Apply Laplace smoothing formula\n",
        "        # P(next_word | current_word) = (Count(current_word, next_word) + 1) / (Count(current_word) + V)\n",
        "        smoothed_probability = (count_bigram + 1) / denominator\n",
        "        possible_next_words_scores[next_word_candidate] = smoothed_probability\n",
        "\n",
        "    if not possible_next_words_scores:\n",
        "        return \"No prediction available (no known next words).\"\n",
        "\n",
        "    # Find the next word with the highest smoothed probability\n",
        "    predicted_word = max(possible_next_words_scores, key=possible_next_words_scores.get)\n",
        "    return predicted_word\n",
        "\n",
        "# Example Usage:\n",
        "# Make sure 'bigram_counts', 'unigram_counts', and 'V' are defined from previous steps\n",
        "if 'bigram_counts' in locals() and 'unigram_counts' in locals() and 'V' in locals():\n",
        "    print(\"\\n--- Bigram Next Word Prediction with Laplace Smoothing ---\")\n",
        "\n",
        "    word_to_predict_1 = \"am\"\n",
        "    prediction_1 = predict_next_word_bigram_laplace(word_to_predict_1, bigram_counts, unigram_counts, V)\n",
        "    print(f\"Given '{word_to_predict_1}', smoothed predicted next word: '{prediction_1}'\")\n",
        "\n",
        "    word_to_predict_2 = \"research\"\n",
        "    prediction_2 = predict_next_word_bigram_laplace(word_to_predict_2, bigram_counts, unigram_counts, V)\n",
        "    print(f\"Given '{word_to_predict_2}', smoothed predicted next word: '{prediction_2}'\")\n",
        "\n",
        "    word_to_predict_3 = \"newword\" # A word not seen before\n",
        "    prediction_3 = predict_next_word_bigram_laplace(word_to_predict_3, bigram_counts, unigram_counts, V)\n",
        "    print(f\"Given '{word_to_predict_3}', smoothed predicted next word: '{prediction_3}'\")\n",
        "\n",
        "    word_to_predict_4 = \"jntuh\" # A word seen, but perhaps rare or at end of sentence in training\n",
        "    prediction_4 = predict_next_word_bigram_laplace(word_to_predict_4, bigram_counts, unigram_counts, V)\n",
        "    print(f\"Given '{word_to_predict_4}', smoothed predicted next word: '{prediction_4}'\")\n",
        "else:\n",
        "    print(\"Error: bigram_counts, unigram_counts, or V not found. Please ensure relevant cells have been executed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzrGPjoxT7Zx",
        "outputId": "ed87dc9e-d411-42a0-97e9-8b1591c38359"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Bigram Next Word Prediction with Laplace Smoothing ---\n",
            "Given 'am', smoothed predicted next word: 'teaching'\n",
            "Given 'research', smoothed predicted next word: 'projects'\n",
            "Given 'newword', smoothed predicted next word: 'No prediction available for this word (not in vocabulary).'\n",
            "Given 'jntuh', smoothed predicted next word: 'i'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=input(\"enter text\").lower()\n",
        "words_from_input = text.split()\n",
        "\n",
        "if len(words_from_input) >= 1:\n",
        "    current_word_for_prediction = words_from_input[-1] # For bigram prediction, we need the last word\n",
        "    next_word1 = predict_next_word_bigram_laplace(current_word_for_prediction, bigram_counts, unigram_counts, V)\n",
        "    print(f\"Given sequence: '{text}', predicted next word: '{next_word1}'\")\n",
        "else:\n",
        "    print(f\"Given sequence: '{text}', please enter at least one word for bigram prediction.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6q3_sVYVmIC",
        "outputId": "df6feac1-0f99-499b-e960-f84e3e1fa976"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti attend\n",
            "Given sequence: 'i attend', predicted next word: 'academic'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using Bi-Gram  with Add K Smoothening"
      ],
      "metadata": {
        "id": "ePZ5BSmJUK10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Function for Next Word Prediction Using Bi-Gram Counts with Add-k Smoothing\n",
        "def predict_next_word_bigram_add_k_smoothing(current_word, bigram_counts, unigram_counts, vocabulary_size, k=0.1):\n",
        "    possible_next_words_scores = collections.defaultdict(float)\n",
        "\n",
        "    # Get count of the current word\n",
        "    count_current_word = unigram_counts.get(current_word, 0)\n",
        "\n",
        "    # If the current word itself is not in the vocabulary, we can't predict based on bigrams\n",
        "    if count_current_word == 0:\n",
        "        return \"No prediction available for this word (not in vocabulary).\"\n",
        "\n",
        "    # Calculate denominator for Add-k smoothing: Count(current_word) + k * V\n",
        "    # Where V is the vocabulary_size\n",
        "    denominator = count_current_word + k * vocabulary_size\n",
        "\n",
        "    # Iterate through all possible next words (all words in the vocabulary)\n",
        "    all_words_in_vocab = list(unigram_counts.keys())\n",
        "    for next_word_candidate in all_words_in_vocab:\n",
        "        # Get count of the bigram (current_word, next_word_candidate)\n",
        "        bigram_tuple = (current_word, next_word_candidate)\n",
        "        count_bigram = bigram_counts.get(bigram_tuple, 0)\n",
        "\n",
        "        # Apply Add-k smoothing formula\n",
        "        # P(next_word | current_word) = (Count(current_word, next_word) + k) / (Count(current_word) + k * V)\n",
        "        smoothed_probability = (count_bigram + k) / denominator\n",
        "        possible_next_words_scores[next_word_candidate] = smoothed_probability\n",
        "\n",
        "    if not possible_next_words_scores:\n",
        "        return \"No prediction available (no known next words after smoothing).\"\n",
        "\n",
        "    # Find the next word with the highest smoothed probability\n",
        "    predicted_word = max(possible_next_words_scores, key=possible_next_words_scores.get)\n",
        "    return predicted_word\n",
        "\n",
        "# Example Usage:\n",
        "# Make sure 'bigram_counts', 'unigram_counts', and 'V' are defined from previous steps\n",
        "if 'bigram_counts' in locals() and 'unigram_counts' in locals() and 'V' in locals():\n",
        "    print(\"\\n--- Bigram Next Word Prediction with Add-k Smoothing ---\")\n",
        "\n",
        "    # Example with k=1 (Laplace smoothing)\n",
        "    word_to_predict_1 = \"am\"\n",
        "    prediction_1_k1 = predict_next_word_bigram_add_k_smoothing(word_to_predict_1, bigram_counts, unigram_counts, V, k=1)\n",
        "    print(f\"Given '{word_to_predict_1}', with k=1, predicted next word: '{prediction_1_k1}'\")\n",
        "\n",
        "    # Example with k=0.5\n",
        "    word_to_predict_2 = \"research\"\n",
        "    prediction_2_k05 = predict_next_word_bigram_add_k_smoothing(word_to_predict_2, bigram_counts, unigram_counts, V, k=0.5)\n",
        "    print(f\"Given '{word_to_predict_2}', with k=0.5, predicted next word: '{prediction_2_k05}'\")\n",
        "\n",
        "    # Example with a word not seen in bigrams, but in vocab (jntuh) and a small k\n",
        "    word_to_predict_3 = \"jntuh\"\n",
        "    prediction_3_k01 = predict_next_word_bigram_add_k_smoothing(word_to_predict_3, bigram_counts, unigram_counts, V, k=0.1)\n",
        "    print(f\"Given '{word_to_predict_3}', with k=0.1, predicted next word: '{prediction_3_k01}'\")\n",
        "\n",
        "    # Example with a word not in the vocabulary at all\n",
        "    word_to_predict_4 = \"nonexistentword\"\n",
        "    prediction_4_k1 = predict_next_word_bigram_add_k_smoothing(word_to_predict_4, bigram_counts, unigram_counts, V, k=1)\n",
        "    print(f\"Given '{word_to_predict_4}', with k=1, predicted next word: '{prediction_4_k1}'\")\n",
        "\n",
        "else:\n",
        "    print(\"Error: bigram_counts, unigram_counts, or V not found. Please ensure relevant cells have been executed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmqCRmFYULYd",
        "outputId": "a25d70db-5c5a-4acc-a11a-7ff972ba2c00"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Bigram Next Word Prediction with Add-k Smoothing ---\n",
            "Given 'am', with k=1, predicted next word: 'teaching'\n",
            "Given 'research', with k=0.5, predicted next word: 'projects'\n",
            "Given 'jntuh', with k=0.1, predicted next word: 'i'\n",
            "Given 'nonexistentword', with k=1, predicted next word: 'No prediction available for this word (not in vocabulary).'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=input(\"enter text\").lower()\n",
        "words_from_input = text.split()\n",
        "\n",
        "if len(words_from_input) >= 1:\n",
        "    current_word_for_prediction = words_from_input[-1] # For  prediction, we need the last word\n",
        "    next_word1 = predict_next_word_bigram_add_k_smoothing(current_word_for_prediction, bigram_counts, unigram_counts, V)\n",
        "    print(f\"Given sequence: '{text}', predicted next word: '{next_word1}'\")\n",
        "else:\n",
        "    print(f\"Given sequence: '{text}', please enter at least one word for bigram prediction.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZqEUvZZW8m9",
        "outputId": "b33a7d10-d89e-4ea0-e5a4-49674040c831"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti serve\n",
            "Given sequence: 'i serve', predicted next word: 'on'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using tri-Gram with Laplace Smoothening"
      ],
      "metadata": {
        "id": "GhDZ8kD3U7ZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Function for Next Word Prediction Using Tri-Gram Counts with Laplace Smoothing (k=1)\n",
        "def predict_next_word_trigram_laplace(current_word_1, current_word_2, trigram_counts, bigram_counts, vocabulary_size):\n",
        "    return predict_next_word_trigram_add_k_smoothing(current_word_1, current_word_2, trigram_counts, bigram_counts, vocabulary_size, k=1)\n",
        "\n",
        "# Example Usage:\n",
        "# Make sure 'trigram_counts', 'bigram_counts', 'unigram_counts', and 'V' are defined from previous steps\n",
        "if 'trigram_counts' in locals() and 'bigram_counts' in locals() and 'unigram_counts' in locals() and 'V' in locals():\n",
        "    print(\"\\n--- Trigram Next Word Prediction with Laplace Smoothing (k=1) ---\")\n",
        "\n",
        "    # Example 1: Predict after ('i', 'am')\n",
        "    word_to_predict_1a = \"i\"\n",
        "    word_to_predict_1b = \"am\"\n",
        "    prediction_1 = predict_next_word_trigram_laplace(word_to_predict_1a, word_to_predict_1b, trigram_counts, bigram_counts, V)\n",
        "    print(f\"Given '{word_to_predict_1a}' and '{word_to_predict_1b}', with Laplace Smoothing, predicted next word: '{prediction_1}'\")\n",
        "\n",
        "    # Example 2: Predict after ('computer', 'science')\n",
        "    word_to_predict_2a = \"computer\"\n",
        "    word_to_predict_2b = \"science\"\n",
        "    prediction_2 = predict_next_word_trigram_laplace(word_to_predict_2a, word_to_predict_2b, trigram_counts, bigram_counts, V)\n",
        "    print(f\"Given '{word_to_predict_2a}' and '{word_to_predict_2b}', with Laplace Smoothing, predicted next word: '{prediction_2}'\")\n",
        "\n",
        "    # Example 3: Predict after a bigram not in the corpus but both words are in vocabulary\n",
        "    word_to_predict_3a = \"computer\"\n",
        "    word_to_predict_3b = \"working\"\n",
        "    prediction_3 = predict_next_word_trigram_laplace(word_to_predict_3a, word_to_predict_3b, trigram_counts, bigram_counts, V)\n",
        "    print(f\"Given '{word_to_predict_3a}' and '{word_to_predict_3b}', with Laplace Smoothing, predicted next word: '{prediction_3}'\")\n",
        "\n",
        "else:\n",
        "    print(\"Error: trigram_counts, bigram_counts, unigram_counts, or V not found. Please ensure relevant cells have been executed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdLidcXVVAbm",
        "outputId": "2cefc8ce-afdd-4a1e-8596-4eed57874338"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Trigram Next Word Prediction with Laplace Smoothing (k=1) ---\n",
            "Given 'i' and 'am', with Laplace Smoothing, predicted next word: 'teaching'\n",
            "Given 'computer' and 'science', with Laplace Smoothing, predicted next word: 'courses'\n",
            "Given 'computer' and 'working', with Laplace Smoothing, predicted next word: 'i'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=input(\"enter text\").lower()\n",
        "words_from_input = text.split()\n",
        "\n",
        "if len(words_from_input) >= 2:\n",
        "    word1, word2 = words_from_input[-2], words_from_input[-1] # Take the last two words for prediction\n",
        "    next_word1 = predict_next_word_trigram_laplace(word1, word2, trigram_counts, bigram_counts, V)\n",
        "    print(f\"Given sequence: '{text}', predicted next word: '{next_word1}'\")\n",
        "elif len(words_from_input) == 1:\n",
        "    print(f\"Given sequence: '{text}', trigram prediction requires at least two words preceding.\")\n",
        "else:\n",
        "    print(f\"Given sequence: '{text}', please enter at least two words for trigram prediction.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlS22ueqXLwM",
        "outputId": "af653533-5591-49a4-927c-1c65c768f8a8"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti completed my\n",
            "Given sequence: 'i completed my', predicted next word: 'bachelor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next Word Prediction Using tri-Gram with Add K Smoothening"
      ],
      "metadata": {
        "id": "I4ObaifRUjw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "\n",
        "# Function for Next Word Prediction Using Tri-Gram Counts with Add-k Smoothing\n",
        "def predict_next_word_trigram_add_k_smoothing(current_word_1, current_word_2, trigram_counts, bigram_counts, vocabulary_size, k=1):\n",
        "    possible_next_words_scores = collections.defaultdict(float)\n",
        "\n",
        "    # Get count of the bigram (current_word_1, current_word_2)\n",
        "    # This count will be used in the denominator for trigram probability\n",
        "    bigram_context_tuple = (current_word_1, current_word_2)\n",
        "    count_bigram_context = bigram_counts.get(bigram_context_tuple, 0)\n",
        "\n",
        "    # If the bigram context itself is not found, we can't predict based on trigrams.\n",
        "    # However, with smoothing, we still provide a chance for new words.\n",
        "    # The denominator for Add-k smoothing for trigrams is Count(w_i-1, w_i-2) + k * V\n",
        "    denominator = count_bigram_context + k * vocabulary_size\n",
        "\n",
        "    # If denominator is zero, it means the context bigram was never seen AND k*V is zero (which shouldn't happen if V or k > 0)\n",
        "    if denominator == 0:\n",
        "        return \"No prediction available (denominator is zero, check bigram context or vocabulary).\"\n",
        "\n",
        "    # Iterate through all possible next words (all words in the vocabulary)\n",
        "    # We need access to all words to assign smoothed probabilities even to unseen trigrams.\n",
        "    all_words_in_vocab = list(unigram_counts.keys()) # Assuming unigram_counts is available globally\n",
        "    for next_word_candidate in all_words_in_vocab:\n",
        "        # Get count of the trigram (current_word_1, current_word_2, next_word_candidate)\n",
        "        trigram_tuple = (current_word_1, current_word_2, next_word_candidate)\n",
        "        count_trigram = trigram_counts.get(trigram_tuple, 0)\n",
        "\n",
        "        # Apply Add-k smoothing formula\n",
        "        # P(w_i | w_i-1, w_i-2) = (Count(w_i-2, w_i-1, w_i) + k) / (Count(w_i-2, w_i-1) + k * V)\n",
        "        smoothed_probability = (count_trigram + k) / denominator\n",
        "        possible_next_words_scores[next_word_candidate] = smoothed_probability\n",
        "\n",
        "    if not possible_next_words_scores:\n",
        "        return \"No prediction available (no known next words after smoothing).\"\n",
        "\n",
        "    # Find the next word with the highest smoothed probability\n",
        "    predicted_word = max(possible_next_words_scores, key=possible_next_words_scores.get)\n",
        "    return predicted_word\n",
        "\n",
        "# Example Usage:\n",
        "# Make sure 'trigram_counts', 'bigram_counts', 'unigram_counts', and 'V' are defined from previous steps\n",
        "if 'trigram_counts' in locals() and 'bigram_counts' in locals() and 'unigram_counts' in locals() and 'V' in locals():\n",
        "    print(\"\\n--- Trigram Next Word Prediction with Add-k Smoothing ---\")\n",
        "\n",
        "    # Example 1: Predict after ('i', 'am') with k=1 (Laplace smoothing)\n",
        "    word_to_predict_1a = \"i\"\n",
        "    word_to_predict_1b = \"am\"\n",
        "    prediction_1_k1 = predict_next_word_trigram_add_k_smoothing(word_to_predict_1a, word_to_predict_1b, trigram_counts, bigram_counts, V, k=1)\n",
        "    print(f\"Given '{word_to_predict_1a}' and '{word_to_predict_1b}', with k=1, predicted next word: '{prediction_1_k1}'\")\n",
        "\n",
        "    # Example 2: Predict after ('research', 'projects') with k=0.5\n",
        "    word_to_predict_2a = \"research\"\n",
        "    word_to_predict_2b = \"projects\"\n",
        "    prediction_2_k05 = predict_next_word_trigram_add_k_smoothing(word_to_predict_2a, word_to_predict_2b, trigram_counts, bigram_counts, V, k=0.5)\n",
        "    print(f\"Given '{word_to_predict_2a}' and '{word_to_predict_2b}', with k=0.5, predicted next word: '{prediction_2_k05}'\")\n",
        "\n",
        "    # Example 3: Predict after a less common bigram, e.g., ('degree', 'in') with k=0.1\n",
        "    word_to_predict_3a = \"degree\"\n",
        "    word_to_predict_3b = \"in\"\n",
        "    prediction_3_k01 = predict_next_word_trigram_add_k_smoothing(word_to_predict_3a, word_to_predict_3b, trigram_counts, bigram_counts, V, k=0.1)\n",
        "    print(f\"Given '{word_to_predict_3a}' and '{word_to_predict_3b}', with k=0.1, predicted next word: '{prediction_3_k01}'\")\n",
        "\n",
        "    # Example 4: Predict after a bigram not in the corpus but both words are in vocabulary, with k=1\n",
        "    # This is a hypothetical case to show smoothing's effect on unseen contexts\n",
        "    # Let's say ('computer', 'working') is not in bigrams, but 'computer' and 'working' are.\n",
        "    word_to_predict_4a = \"computer\"\n",
        "    word_to_predict_4b = \"working\"\n",
        "    prediction_4_k1 = predict_next_word_trigram_add_k_smoothing(word_to_predict_4a, word_to_predict_4b, trigram_counts, bigram_counts, V, k=1)\n",
        "    print(f\"Given '{word_to_predict_4a}' and '{word_to_predict_4b}', with k=1, predicted next word: '{prediction_4_k1}'\")\n",
        "\n",
        "else:\n",
        "    print(\"Error: trigram_counts, bigram_counts, unigram_counts, or V not found. Please ensure relevant cells have been executed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R94U1WiMULcE",
        "outputId": "8760e2ae-0542-46f4-c851-c3a9446a70ce"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Trigram Next Word Prediction with Add-k Smoothing ---\n",
            "Given 'i' and 'am', with k=1, predicted next word: 'teaching'\n",
            "Given 'research' and 'projects', with k=0.5, predicted next word: 'i'\n",
            "Given 'degree' and 'in', with k=0.1, predicted next word: 'jntuh'\n",
            "Given 'computer' and 'working', with k=1, predicted next word: 'i'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=input(\"enter text\").lower()\n",
        "words_from_input = text.split()\n",
        "\n",
        "if len(words_from_input) >= 2:\n",
        "    word1, word2 = words_from_input[-2], words_from_input[-1] # Take the last two words for prediction\n",
        "    next_word1 = predict_next_word_trigram_add_k_smoothing(word1, word2, trigram_counts, bigram_counts, V)\n",
        "    print(f\"Given sequence: '{text}', predicted next word: '{next_word1}'\")\n",
        "elif len(words_from_input) == 1:\n",
        "    print(f\"Given sequence: '{text}', trigram prediction requires at least two words preceding.\")\n",
        "else:\n",
        "    print(f\"Given sequence: '{text}', please enter at least two words for trigram prediction.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8YF9MkPXmIn",
        "outputId": "cf3170aa-ae33-41f8-f79d-f546c9a6e307"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "enter texti collaborate with\n",
            "Given sequence: 'i collaborate with', predicted next word: 'faculty'\n"
          ]
        }
      ]
    }
  ]
}